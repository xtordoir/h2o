{
  "metadata" : {
    "name" : "GetStarted",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : "/root/.m2/repository",
    "customRepos" : null,
    "customDeps" : [ "ai.h2o % sparkling-water-core_2.10 % 1.3.7", "ai.h2o % h2o-algos % 3.0.0.26", "org.bdgenomics.adam % adam-core % 0.16.0", "org.scala-lang % jline % 2.10.4", "- log4j % log4j % 1.2.15", "- org.apache.hadoop % hadoop-client %   _", "- org.apache.spark  % spark-core_2.10    %   _", "- org.apache.spark % spark-mllib_2.10 % _", "- org.apache.spark % spark-repl_2.10 % _", "- org.scala-lang    %     _         %   _", "- org.scoverage     %     _         %   _" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : {
      "spark.executor.memory" : "13g"
    }
  },
  "cells" : [ {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import water.parser._\nimport hex.FrameSplitter\nimport water.Key\nimport org.apache.spark.h2o.H2OContext",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import water.parser._\nimport hex.FrameSplitter\nimport water.Key\nimport org.apache.spark.h2o.H2OContext\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.rdd.RDD\nval sqlContext = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.Row",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.rdd.RDD\nsqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@79f24a12\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.Row\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.h2o.H2OContext",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.h2o.H2OContext\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 3
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "water.H2O.CLOUD.size()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res2: Int = 0\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "0"
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val h2oContext = new H2OContext(sparkContext).start()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "h2oContext: org.apache.spark.h2o.H2OContext = \n\nSparkling Water Context:\n * number of executors: 3\n * list of used executors:\n  (executorId, host, port)\n  ------------------------\n  (0,ip-10-184-0-223.eu-west-1.compute.internal,54321)\n  (2,ip-10-184-2-40.eu-west-1.compute.internal,54321)\n  (1,ip-10-9-2-31.eu-west-1.compute.internal,54321)\n  ------------------------\n\n  Open H2O Flow in browser: http://10.13.12.179:54321 (CMD + click in Mac OSX)\n    \n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "\nSparkling Water Context:\n * number of executors: 3\n * list of used executors:\n  (executorId, host, port)\n  ------------------------\n  (0,ip-10-184-0-223.eu-west-1.compute.internal,54321)\n  (2,ip-10-184-2-40.eu-west-1.compute.internal,54321)\n  (1,ip-10-9-2-31.eu-west-1.compute.internal,54321)\n  ------------------------\n\n  Open H2O Flow in browser: http://10.13.12.179:54321 (CMD + click in Mac OSX)\n    "
      },
      "output_type" : "execute_result",
      "execution_count" : 4
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import h2oContext._",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import h2oContext._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "<console>:69: error: not found: value dataFrame\n       val frameSplitter = new FrameSplitter(dataFrame, Array(.5, .3), Array(\"training\", \"test\", \"validation\").map(Key.make), null)\n                                             ^\n"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : " case class MyCase(x: Double, i: Int, c: String) extends java.io.Serializable\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class MyCase\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val df = globalScope.sparkContext.parallelize( (1 to 100).map(i => MyCase(i*1.0, i, i.toString)) ).toDF()\n()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "warning: there were 1 feature warning(s); re-run with -feature for details\ndf: org.apache.spark.sql.DataFrame = [x: double, i: int, c: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val hf = h2oContext.asH2OFrame(df)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "hf: org.apache.spark.h2o.H2OFrame = \nFrame frame_rdd_6 (100 rows and 3 cols):\n           x    i   c\n    min    1    1    \n   mean   50   50    \n stddev   29   29    \n    max  100  100    \nmissing    0    0    \n      0    1    1   1\n      1    2    2   2\n      2    3    3   3\n      3    4    4   4\n      4    5    5   5\n      5    6    6   6\n      6    7    7   7\n      7    8    8   8\n      8    9    9   9\n      9   10   10  10\n     10   11   11  11\n     11   12   12  12\n     12   13   13  13\n     13   14   14  14\n     14   15   15  15\n     15   16   16  16\n     16   17   17  17\n     17   18   18  18\n     18   19   19  19\n     19   20   20  20\n\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "Frame frame_rdd_6 (100 rows and 3 cols):\n           x    i   c\n    min    1    1    \n   mean   50   50    \n stddev   29   29    \n    max  100  100    \nmissing    0    0    \n      0    1    1   1\n      1    2    2   2\n      2    3    3   3\n      3    4    4   4\n      4    5    5   5\n      5    6    6   6\n      6    7    7   7\n      7    8    8   8\n      8    9    9   9\n      9   10   10  10\n     10   11   11  11\n     11   12   12  12\n     12   13   13  13\n     13   14   14  14\n     14   15   15  15\n     15   16   16  16\n     16   17   17  17\n     17   18   18  18\n     18   19   19  19\n     19   20   20  20\n"
      },
      "output_type" : "execute_result",
      "execution_count" : 7
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val frameSplitter = new FrameSplitter(hf, Array(.5, .3), Array(\"training\", \"test\", \"validation\").map(Key.make), null)\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "frameSplitter: hex.FrameSplitter = hex.FrameSplitter@bb7d63f\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "hex.FrameSplitter@bb7d63f"
      },
      "output_type" : "execute_result",
      "execution_count" : 10
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import scala.collection.JavaConverters._\nval arr: Array[water.Key[water.fvec.Frame]] = Array(\"training\", \"test\", \"validation\").map(s => Key.make[water.fvec.Frame](s))\n\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "<console>:65: error: overloaded method value make with alternatives:\n  (x$1: Byte,x$2: Byte,x$3: Boolean,x$4: <repeated...>[water.H2ONode])water.Key[_ <: water.Keyed[_ <: AnyRef]] <and>\n  (x$1: String,x$2: Byte,x$3: Byte,x$4: Boolean,x$5: <repeated...>[water.H2ONode])water.Key[_ <: water.Keyed[_ <: AnyRef]] <and>\n  ()water.Key[_ <: water.Keyed[_ <: AnyRef]] <and>\n  (x$1: water.H2ONode)water.Key[_ <: water.Keyed[_ <: AnyRef]] <and>\n  (x$1: String)water.Key[_ <: water.Keyed[_ <: AnyRef]] <and>\n  (x$1: Array[Byte])water.Key[_ <: water.Keyed[_ <: AnyRef]]\n does not take type parameters\n       val arr: Array[water.Key[water.fvec.Frame]] = Array(\"training\", \"test\", \"validation\").map(s => Key.make[water.fvec.Frame](s))\n                                                                                                          ^\n"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "Key.make[water.fvec.Frame](\"hello\")",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val frameSplitter = new FrameSplitter(hf, Array(.5, .3), arr, null)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "<console>:69: error: not found: value hf\n       val frameSplitter = new FrameSplitter(hf, Array(.5, .3), arr, null)\n                                             ^\n"
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "    water.H2O.submitTask(frameSplitter)\n    val splits = frameSplitter.getResult\n    val training = splits(0)\n    val validation = splits(2)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "splits: Array[water.fvec.Frame] = \nArray(Frame training (50 rows and 3 cols):\n          x   i   c\n    min   1   1    \n   mean  25  25    \n stddev  14  14    \n    max  50  50    \nmissing   0   0    \n      0   1   1   1\n      1   2   2   2\n      2   3   3   3\n      3   4   4   4\n      4   5   5   5\n      5   6   6   6\n      6   7   7   7\n      7   8   8   8\n      8   9   9   9\n      9  10  10  10\n     10  11  11  11\n     11  12  12  12\n     12  13  13  13\n     13  14  14  14\n     14  15  15  15\n     15  16  16  16\n     16  17  17  17\n     17  18  18  18\n     18  19  19  19\n     19  20  20  20\n, Frame test (30 rows and 3 cols):\n          x   i   c\n    min  51  51    \n   mean  65  65    \n stddev   8   8    \n    max  80  80    \nmissing   0   0    \n      0  51  51  51\n      1  52  52  52\n    ..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "Frame validation (20 rows and 3 cols):\n           x    i    c\n    min   81   81     \n   mean   90   90     \n stddev    5    5     \n    max  100  100     \nmissing    0    0     \n      0   81   81   81\n      1   82   82   82\n      2   83   83   83\n      3   84   84   84\n      4   85   85   85\n      5   86   86   86\n      6   87   87   87\n      7   88   88   88\n      8   89   89   89\n      9   90   90   90\n     10   91   91   91\n     11   92   92   92\n     12   93   93   93\n     13   94   94   94\n     14   95   95   95\n     15   96   96   96\n     16   97   97   97\n     17   98   98   98\n     18   99   99   99\n     19  100  100  100\n"
      },
      "output_type" : "execute_result",
      "execution_count" : 11
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "training",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "Array(\"training\", \"test\", \"validation\").map(s => Key.make(s))",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}